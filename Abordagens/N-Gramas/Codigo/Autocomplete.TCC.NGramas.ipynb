{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating suggestions for writing source code in C# language based on NLP.\n",
    "\n",
    "\n",
    "## N-Gram approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook was created and adapted for the work of generating suggestions using some ideas and codes as reference the notebook of the author \"Mangeshkar, Saurav\" available at: \n",
    "https://www.kaggle.com/sauravmaheshkar/auto-completion-using-n-gram-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ntpath   \n",
    "from chardet import detect\n",
    "import nltk\n",
    "import re\n",
    "import h5py\n",
    "import numpy as np\n",
    "from toolz import unique\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_list_to_data_file(data, file_name):\n",
    "    \"\"\"\n",
    "    Description: Function to export data to data file.\n",
    "    :param data: Data to export,\n",
    "    :param file_name: File name to export.\n",
    "    \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_name, 'wb') as filehandle:\n",
    "        pickle.dump(data, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_data_file(file_name):\n",
    "    \"\"\"\n",
    "    Description: Function to load data from file.\n",
    "    :param file_name: file name to load data from.\n",
    "    \n",
    "    :return: Type(list): List with data loaded from file.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "\n",
    "    with open(file_name, 'rb') as filehandle:\n",
    "        data = pickle.load(filehandle)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(title, message = None, new_line = False):\n",
    "    \"\"\"\n",
    "    Description: Function to print info on screen.\n",
    "    :param title: Message title,\n",
    "    :param message: Message to print,\n",
    "    :param new_line: Indicates whether the first message will start with a line break or not.\n",
    "    \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    if new_line:\n",
    "        print('\\n')\n",
    "    \n",
    "    print(\"####################################\")\n",
    "    print(title)\n",
    "    print(\"####################################\")\n",
    "    \n",
    "    if message:\n",
    "        print(\"%s\\n\" % (message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_of_numbers_from_string(str):\n",
    "    \"\"\"\n",
    "    Description: Function to extract all the sequence of numbers from the given string.\n",
    "    :param str: String to extract sequence of numbers.\n",
    "    \n",
    "    :return: Type(list): List with sequence of numbers.\n",
    "    \"\"\"\n",
    "    \n",
    "    array_numbers = re.findall(r'[0-9]+', str)\n",
    "    \n",
    "    return array_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sequence_of_numbers_for_mask(str_to_replace, \n",
    "                                         array_sequence_numbers_to_search, \n",
    "                                         mask_to_replace):\n",
    "    \"\"\"\n",
    "    Description: Function to replace sequence of numbers for specific mask.\n",
    "    :param str_to_replace: String to replace sequence of numbers,\n",
    "    :param array_sequence_numbers_to_search: Sequence numbers to search for,\n",
    "    :param mask_to_replace: Mask to replace each sequence.\n",
    "    \n",
    "    :return: Type(String): String with sequence of numbers replaced by mask.\n",
    "    \"\"\"\n",
    "    \n",
    "    for number_sequence in array_sequence_numbers_to_search:\n",
    "        str_to_replace = re.sub(str(number_sequence), mask_to_replace, str_to_replace, 1)\n",
    "\n",
    "    return str_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_type(file_path):\n",
    "    \"\"\"\n",
    "    Description: Function to retrieve enconding type of file.\n",
    "    :param file_path: File to get enconding.\n",
    "    \n",
    "    :return: Type(String): String with enconding type of file.\n",
    "    \"\"\"\n",
    "        \n",
    "    with open(file_path, 'rb') as f:\n",
    "        rawdata = f.read()\n",
    "    return detect(rawdata)['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_enconding(source_file, enconding):\n",
    "    \"\"\"\n",
    "    Description: Function to change enconding of file.\n",
    "    :param source_file: File path to change enconding,\n",
    "    :param enconding: Enconding to replace in source_file.\n",
    "    \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    from_codec = get_encoding_type(source_file)\n",
    "    \n",
    "    try: \n",
    "        target_file = source_file.replace(ntpath.basename(source_file), \"123%s\" % (ntpath.basename(source_file))) \n",
    "        \n",
    "        with open(source_file, 'r', encoding=from_codec) as f, open(target_file, 'w', encoding=enconding) as e:\n",
    "                text = f.read()\n",
    "                e.write(text)\n",
    "                f.close()\n",
    "\n",
    "        os.remove(source_file) \n",
    "        os.rename(target_file, source_file) \n",
    "        \n",
    "    except UnicodeDecodeError:\n",
    "        print(\"Decode error for file: '%s'\" % (source_file))\n",
    "    except UnicodeEncodeError:\n",
    "        print(\"Encode error for file: '%s'\" % (source_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list(list_to_flatten):\n",
    "    \"\"\"\n",
    "    Description: Function to flatten the given list.\n",
    "    :param list_to_flatten: List to flatten.\n",
    "    \n",
    "    :return: Type(List): Flat list.\n",
    "    \"\"\"   \n",
    "    \n",
    "    return [f for child_list in list_to_flatten for f in child_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_items_from_list(list_to_remove_duplicates):\n",
    "    \"\"\"\n",
    "    Description: Function to remove duplicate itens from given list.\n",
    "    :param list_to_remove_duplicates: List to remove duplicates.\n",
    "    \n",
    "    :return: Type(List): List without duplicates.\n",
    "    \"\"\"  \n",
    "    \n",
    "    return list(map(list, unique(map(tuple, list_to_remove_duplicates))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_test_previous_tokens_list(csv_file_path):\n",
    "    \"\"\"\n",
    "    Description: Function to load data from csv file to previous tokens list.\n",
    "    :param csv_file_path: Csv file path with data for previous tokens .\n",
    "    \n",
    "    :return: Type(List): List with previous tokens.\n",
    "    \"\"\"\n",
    "        \n",
    "    dataframe_tokens_test = pd.read_csv(csv_file_path, delimiter=\";\", header=None)\n",
    "\n",
    "    previous_tokens_list = []\n",
    "\n",
    "    for index, row in dataframe_tokens_test.iterrows():\n",
    "        token = \"\"\n",
    "        for column in range(len(dataframe_tokens_test.columns.tolist())):\n",
    "            if type(row[column]) == str:\n",
    "                token += row[column] + \" \"\n",
    "\n",
    "        previous_tokens_list.append(token[:-1])\n",
    "\n",
    "    return previous_tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_suggestions_to_csv_file(csv_file_path, all_suggestions):\n",
    "    \"\"\"\n",
    "    Description: Function to save suggestions into csv file.\n",
    "    :param csv_file_path: Csv file path to save suggestions,\n",
    "    :param all_suggestions: List with all sugestions to save in csv file.\n",
    "    \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    data_to_save_in_csv = []\n",
    "\n",
    "    for suggestions in all_suggestions:\n",
    "        for i in range(len(suggestions[1])):\n",
    "            data_to_save_in_csv.append([suggestions[0], suggestions[1][i]])\n",
    "\n",
    "    with open(csv_file_path, 'w', newline='') as f:     \n",
    "        write = csv.writer(f, delimiter=\";\")      \n",
    "        write.writerows(data_to_save_in_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C# repository functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_c_sharp_complete_file_names_for_each_class(root_directory):\n",
    "    \"\"\"\n",
    "    Description: Function to get all complete name of files with extension \".cs\" (C# class).\n",
    "    :param root_directory: Root directory of files.\n",
    "    \n",
    "    :return: Type(List): List with all file names of C# repository.\n",
    "    \"\"\"\n",
    "    \n",
    "    C_SHARP_CLASS_FILE_EXTENSION = \".cs\"\n",
    "    \n",
    "    complete_name_of_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(root_directory):\n",
    "        for file in files:\n",
    "            if file.endswith(C_SHARP_CLASS_FILE_EXTENSION):\n",
    "                complete_name_of_files.append(os.path.join(root, file))\n",
    "    \n",
    "    return complete_name_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_for_each_file(complete_name_of_files):\n",
    "    \"\"\"\n",
    "    Description: Function to get content of each source code file.\n",
    "    :param complete_name_of_files: List with name of each file downladed from repository.\n",
    "    \n",
    "    :return: Type(List): Corpus with all C# source code.\n",
    "    \"\"\"\n",
    "    \n",
    "    c_sharp_code_corpus = []\n",
    "\n",
    "    for file_name in complete_name_of_files:\n",
    "        try:\n",
    "            with open(file_name, \"r\", encoding=\"utf8\", errors='ignore') as physical_file:\n",
    "                c_sharp_code_corpus.append(physical_file.read())\n",
    "                physical_file.close()\n",
    "        except:\n",
    "            change_enconding(file_name)\n",
    "            \n",
    "    return c_sharp_code_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_code_to_tokens(source_code):\n",
    "    \"\"\"\n",
    "    Description: Function to make pre-processing in source code and tokenize words.\n",
    "    :param source_code: Source code to pre-processing.\n",
    "    \n",
    "    :return: Type(List): List of tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    MASK_NUMBERS = \"|mask_number|\"\n",
    "    \n",
    "    code_sentences = source_code.split('\\n')\n",
    "    \n",
    "    code_sentences = [c.strip() for c in code_sentences]\n",
    "    \n",
    "    code_sentences = [c for c in code_sentences if len(c) > 0]\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for piece_of_code  in code_sentences:\n",
    "        token = nltk.word_tokenize(piece_of_code)\n",
    "\n",
    "        for i in range(len(token)):\n",
    "            token[i] = replace_sequence_of_numbers_for_mask(\n",
    "                            token[i],\n",
    "                            get_sequence_of_numbers_from_string(token[i]),\n",
    "                            MASK_NUMBERS)\n",
    "            \n",
    "        tokens.append(token)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_all_files(c_sharp_code_corpus, first_x_corpus = 0):\n",
    "    \"\"\"\n",
    "    Description: Function to tokenize all files.\n",
    "    :param c_sharp_code_corpus: Complete list of C# corpus (Source code).\n",
    "    :param first_x_corpus: Option to tokenize only the first X elements. Default: 0 - Tokenize all files.\n",
    "    \n",
    "    :return: Type(List): List of tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    corpus_copy = c_sharp_code_corpus[:]\n",
    "    \n",
    "    if first_x_corpus > 0:\n",
    "        corpus_copy = corpus_copy[:first_x_corpus]\n",
    "        \n",
    "    for corpus in corpus_copy:\n",
    "        tokens.append(preprocess_code_to_tokens(corpus))\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_the_words_for_code(code_tokens):\n",
    "    \"\"\"\n",
    "    Description: Function to count words for source codes.\n",
    "    :param code_tokens: Tokens of all source repository.\n",
    "\n",
    "    :return: Type(Dictionary): Dictionary with words count { Key - \"Word\", Value = Count }.\n",
    "    \"\"\"\n",
    "    \n",
    "    code_counts = {}\n",
    "\n",
    "    for code_token in code_tokens: \n",
    "        for token in code_token:\n",
    "            for token_aux in token:\n",
    "                if token_aux not in code_counts.keys():\n",
    "                    code_counts[token_aux] = 1\n",
    "                else:\n",
    "                    code_counts[token_aux] += 1 \n",
    "            \n",
    "    return code_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_out_of_code_vocabulary(tokens, count_threshold):\n",
    "    \"\"\"\n",
    "    Description: Function to create a dictionary of words (piece of code) that are not present in\n",
    "    current corpus.\n",
    "    :param tokens: List of tokens.\n",
    "    :param count_threshold: Limit of words to add in closed dictionary.\n",
    "    \n",
    "    :return: Type(List): Closed vocabulary.\n",
    "    \"\"\"\n",
    "        \n",
    "    closed_vocabulary = []\n",
    "\n",
    "    words_count = count_the_words_for_code(tokens)\n",
    "    \n",
    "    for word, count in words_count.items():\n",
    "        if count >= count_threshold :\n",
    "            closed_vocabulary.append(word)\n",
    "\n",
    "    return closed_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_tokenize(tokens, vocabulary, unknown_token = \"<unk>\"):\n",
    "    \"\"\"\n",
    "    Description: Function to append list of tokens with unknown words (piece of code).\n",
    "    :param tokens: List of tokens,\n",
    "    :param vocabulary: Vocabulary of code,\n",
    "    :param unknown_token: Unknown token. Default: <unk>\n",
    "    \n",
    "    :return: Type(List): List of tokens with new unknown tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    vocabulary = set(vocabulary)\n",
    "    \n",
    "    new_tokenized_sentences = []\n",
    "    \n",
    "    for sentence in tokens:\n",
    "        new_sentence = []\n",
    "        \n",
    "        for token in sentence:\n",
    "            for token_aux in token:\n",
    "                if token_aux in vocabulary:\n",
    "                    new_sentence.append(token_aux)\n",
    "                else:\n",
    "                    new_sentence.append(unknown_token)\n",
    "\n",
    "        new_tokenized_sentences.append(new_sentence)\n",
    "    \n",
    "    return new_tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_vocabulary_and_unknown(tokens, count_threshold):\n",
    "    \"\"\"\n",
    "    Description: Function to process vocabulary and unknown tokens.\n",
    "    :param tokens: List of tokens,\n",
    "    :param count_threshold: Limit do define wether some word is unknown or not.\n",
    "    \n",
    "    :return: Type(List, List): Tokens list and Vocabulary list.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens_aux = tokens[:]\n",
    "\n",
    "    vocabulary = handling_out_of_code_vocabulary(tokens_aux, count_threshold)\n",
    "\n",
    "    new_token_data = unknown_tokenize(tokens_aux, vocabulary)\n",
    "\n",
    "    return new_token_data, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_n_grams(tokens, ngrams_number, start_token_delimiter = \"<s>\", end_token_delimiter = \"<e>\"):\n",
    "    \"\"\"\n",
    "    Description: Function to count n-grams.\n",
    "    :param tokens: List of tokens,\n",
    "    :param ngrams_number: Number of n-grams,\n",
    "    :param start_token_delimiter: Start token delimiter,\n",
    "    :param end_token_delimiter: End token delimiter.\n",
    "    \n",
    "    :return: Type(Dictionary): Dictionary with n-grams.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_grams = {}\n",
    "\n",
    "    for sentence in tokens:\n",
    "        sentence = [start_token_delimiter]*ngrams_number + sentence + [end_token_delimiter]\n",
    "\n",
    "        sentence = tuple(sentence)\n",
    "\n",
    "        m = len(sentence) if ngrams_number==1 else len(sentence)-1\n",
    "\n",
    "        for i in range(m):\n",
    "            n_gram = sentence[i:i+ngrams_number]\n",
    "\n",
    "            if n_gram in n_grams.keys():\n",
    "                n_grams[n_gram] += 1\n",
    "            else:\n",
    "                n_grams[n_gram] = 1\n",
    "\n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_for_n_gram(word, \n",
    "                    previous_n_gram, \n",
    "                    n_gram_counts, \n",
    "                    nplus1_gram_counts, \n",
    "                    vocabulary_size, \n",
    "                    k = 1.0):\n",
    "    \"\"\"\n",
    "    Description: Function to calculate probability of a single word.\n",
    "    :param word: Word to calculate probability,\n",
    "    :param previous_n_gram: Previous n-gram(token) to calculate probability,\n",
    "    :param n_gram_counts: N-gram list with same size of previous_n_gram,\n",
    "    :param nplus1_gram_counts: N-grams list with one word more than n_gram_counts,\n",
    "    :param vocabulary_size: Vocabulary size,\n",
    "    :param k: k constant to calculate probability with smoothing.\n",
    "    \n",
    "    :return: Type(Float): Probability of a single word.\n",
    "    \"\"\"\n",
    "    \n",
    "    previous_n_gram = tuple(previous_n_gram)\n",
    "    \n",
    "    previous_n_gram_count = n_gram_counts[previous_n_gram] if previous_n_gram in n_gram_counts else 0\n",
    "    \n",
    "    denom = previous_n_gram_count + k * vocabulary_size\n",
    "\n",
    "    nplus1_gram = previous_n_gram + (word,)\n",
    "    \n",
    "    nplus1_gram_count = nplus1_gram_counts[nplus1_gram] if nplus1_gram in nplus1_gram_counts else 0\n",
    "    \n",
    "    num = nplus1_gram_count + k\n",
    "\n",
    "    prob = num / denom\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs(previous_n_gram, n_gram_counts, nplus1_gram_counts, vocabulary, k=1.0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Function to calculate probability of next n-gram.\n",
    "    :param previous_n_gram: Previous n-gram(token) to calculate probability,\n",
    "    :param n_gram_counts: N-gram list with same size of previous_n_gram,\n",
    "    :param nplus1_gram_counts: N-grams list with one word more than n_gram_counts,\n",
    "    :param vocabulary_size: Vocabulary size,\n",
    "    :param k: k constant to calculate probability with smoothing.\n",
    "    \n",
    "    :return: Type(Dictionary): {Word : Probability}.\n",
    "    \"\"\"\n",
    "    if type(previous_n_gram) is not tuple:\n",
    "        previous_n_gram = tuple(previous_n_gram)\n",
    "\n",
    "    vocabulary = vocabulary + [\"<e>\", \"<unk>\"]\n",
    "\n",
    "    vocabulary_size = len(vocabulary)\n",
    "\n",
    "    probabilities = {}\n",
    "\n",
    "    for word in vocabulary:\n",
    "        probability = prob_for_n_gram(word, \n",
    "                                      previous_n_gram, \n",
    "                                      n_gram_counts, \n",
    "                                      nplus1_gram_counts, \n",
    "                                      vocabulary_size, \n",
    "                                      k=k)\n",
    "        \n",
    "        probabilities[word] = probability\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_complete(previous_tokens, n_gram_counts, nplus1_gram_counts, vocabulary, k=1.0, start_with=None):\n",
    "    \"\"\"\n",
    "    Description: Function to complete previous words.\n",
    "    :param previous_tokens: Previous tokens to calculate probability,\n",
    "    :param n_gram_counts: N-gram list with same size of previous_n_gram,\n",
    "    :param nplus1_gram_counts: N-grams list with one word more than n_gram_counts,\n",
    "    :param vocabulary: Vocabulary,\n",
    "    :param k: k constant to calculate probability with smoothing,\n",
    "    :param start_with: Filter to start with token.\n",
    "    \n",
    "    :return: Type(Dictionary): {Word : Probability} Next token and probability (5 biggest probability from dictionary).\n",
    "    \"\"\"\n",
    "    n = len(list(n_gram_counts.keys())[0]) \n",
    "\n",
    "    previous_n_gram = previous_tokens[-n:]\n",
    "\n",
    "    probabilities = probs(previous_n_gram, n_gram_counts, nplus1_gram_counts, vocabulary, k=k)\n",
    "\n",
    "    top_5_values = sorted(probabilities.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    return top_5_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(previous_tokens, n_gram_counts_list, vocabulary, k=1.0, start_with=None):\n",
    "    \"\"\"\n",
    "    Description: Function to get suggestions.\n",
    "    :param previous_tokens: Previous token,\n",
    "    :param n_gram_counts_list: Number of n-grams,\n",
    "    :param vocabulary: Vocabulary,\n",
    "    :param k: k constant to calculate probability with smoothing,\n",
    "    :param start_with: Filter to start with token.\n",
    "    \n",
    "    :return: Type(List): [(Word : Probability)] Next token and probability (5 biggest probability from dictionary).\n",
    "    \"\"\"\n",
    "    count = len(n_gram_counts_list) + 1\n",
    "    \n",
    "    suggestions = []\n",
    "    \n",
    "    count_words_previous_tokens = len(previous_tokens)\n",
    "    \n",
    "    if (count_words_previous_tokens + 1) <= len(n_gram_counts_list):\n",
    "        \n",
    "        n_gram_counts = n_gram_counts_list[count_words_previous_tokens - 1]\n",
    "        \n",
    "        nplus1_gram_counts = n_gram_counts_list[count_words_previous_tokens]\n",
    "        \n",
    "        suggestion = auto_complete(previous_tokens, \n",
    "                                   n_gram_counts,\n",
    "                                   nplus1_gram_counts, \n",
    "                                   vocabulary,\n",
    "                                   k=k, \n",
    "                                   start_with=start_with)\n",
    "        \n",
    "        suggestions.append(suggestion)\n",
    "        \n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions_recursively(previous_tokens, \n",
    "                                n_gram_counts_list, \n",
    "                                vocabulary, \n",
    "                                suggestions_for_all_grams, \n",
    "                                quantity_ngrams_to_generate, \n",
    "                                k=1.0):\n",
    "    \"\"\"\n",
    "    Description: Function to execute all possible suggestions in n-gram level based on first previous token informed.\n",
    "    Observation: This function is recursive, it execute themselve until complete all n-grams leves according\n",
    "    with parameter 'quantity_ngrams_to_generate'.\n",
    "    :param previous_tokens: Previous tokens,\n",
    "    :param n_gram_counts_list: Number of n-grams,\n",
    "    :param vocabulary: Vocabulary,\n",
    "    :param suggestions_for_all_grams: Complete list with all suggestions generated,\n",
    "    :param quantity_ngrams_to_generate: Number of n-grams to generate,\n",
    "    :param k: k constant to calculate probability with smoothing.\n",
    "                 \n",
    "                 \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    suggestions_per_ngram = get_suggestions(previous_tokens, n_gram_counts_list, vocabulary)\n",
    "\n",
    "    suggestions_for_all_grams.append([len(previous_tokens) + 1, previous_tokens, suggestions_per_ngram])\n",
    "    \n",
    "    if len(suggestions_per_ngram) > 0:\n",
    "        for suggestion in suggestions_per_ngram[0]:\n",
    "\n",
    "            previous_token_copied = previous_tokens.copy()\n",
    "            previous_token_copied.append(suggestion[0])\n",
    "\n",
    "            if len(previous_token_copied) <= (quantity_ngrams_to_generate + 1):\n",
    "                get_suggestions_recursively(previous_token_copied, \n",
    "                                            n_gram_counts_list, \n",
    "                                            vocabulary, \n",
    "                                            suggestions_for_all_grams,\n",
    "                                            quantity_ngrams_to_generate + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_save_suggestions_from_csv_file(file_path_to_read_previous_tokens, file_path_to_save_suggestions):\n",
    "    \"\"\"\n",
    "    Description: Function to read csv file with previous tokens, get suggestions for each previous tokens and\n",
    "    save those suggestions into csv file result.\n",
    "    :param file_path_to_read_previous_tokens: Csv file path with previous tokens to get suggestions from,\n",
    "    :param file_path_to_save_suggestions: Csv file path to save suggestions.\n",
    "                 \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_previous_tokens = load_csv_to_test_previous_tokens_list(file_path_to_read_previous_tokens)\n",
    "\n",
    "    all_suggestions = []\n",
    "\n",
    "    for previous_tokens in all_previous_tokens:\n",
    "        suggestions = get_suggestions(previous_tokens.split(' '), n_gram_counts_list, vocabulary)\n",
    "        \n",
    "        if len(suggestions) > 0:      \n",
    "            suggestions_to_save = []\n",
    "\n",
    "            for i in range(len(suggestions[0])):\n",
    "                suggestions_to_save.append(suggestions[0][i][0])\n",
    "\n",
    "            all_suggestions.append((previous_tokens, suggestions_to_save))\n",
    "\n",
    "    save_suggestions_to_csv_file(file_path_to_save_suggestions, all_suggestions)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_5_combinations_top_most(n_grams_list):\n",
    "    \"\"\"\n",
    "    Description: Function to display 5 words combinations that appeared the most in each n-gram for param 'n_grams_list'.\n",
    "    :param n_grams_list: n-gram(s) list to show.\n",
    "    \n",
    "    :return: Void.\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(0, len(n_gram_counts_list)):\n",
    "        n_grams_5_appeared_most = sorted(n_gram_counts_list[i].items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print_info(\"%s-gram(s):\" % (i + 1))\n",
    "        data_for_dataframe = []\n",
    "\n",
    "        for words_and_counts in n_grams_5_appeared_most:\n",
    "            words_together_key = ''.join(words_and_counts[0])\n",
    "            count_words_value = words_and_counts[1]\n",
    "\n",
    "            each_line_dataframe = [words_together_key, count_words_value]\n",
    "\n",
    "            data_for_dataframe.append(each_line_dataframe)\n",
    "\n",
    "        df = pd.DataFrame(data_for_dataframe, columns = ['Words', 'Count'])\n",
    "        display(df)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_words_and_probability(df):\n",
    "    \"\"\"\n",
    "    Description: Function to format words and probability to convert later into dataframe and print on screen.\n",
    "    :param df: Pandas dataframe to format.\n",
    "    \n",
    "    :return: Type(List) Formated list with this configuration [(Previos Tokens, Suggestions, Probability)].\n",
    "    \"\"\"\n",
    "    \n",
    "    formated_results = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        previous_tokens = ' '.join(row['previous_tokens'])\n",
    "        \n",
    "        if len(row['suggestions']) > 0:\n",
    "            for suggestion in row['suggestions'][0]:\n",
    "                formated_results.append((previous_tokens, previous_tokens + \" \" + suggestion[0], suggestion[1]))\n",
    "      \n",
    "    return formated_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_FILE_1_WORD = 'previous_tokens_for_test_1_word.csv'\n",
    "PATH_TO_TEST_FILE_2_WORD = 'previous_tokens_for_test_2_word.csv'\n",
    "PATH_TO_TEST_FILE_3_WORD = 'previous_tokens_for_test_3_word.csv'\n",
    "PATH_TO_TEST_FILE_4_WORD = 'previous_tokens_for_test_4_word.csv'\n",
    "\n",
    "PATH_TO_SAVE_SUGGESTIONS_1_WORD = 'suggestions_1_word.csv'\n",
    "PATH_TO_SAVE_SUGGESTIONS_2_WORD = 'suggestions_2_word.csv'\n",
    "PATH_TO_SAVE_SUGGESTIONS_3_WORD = 'suggestions_3_word.csv'\n",
    "PATH_TO_SAVE_SUGGESTIONS_4_WORD = 'suggestions_4_word.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and filter C# class files (.cs) from root repository downladed from: https://github.com/dotnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "First 10 files:\n",
      "####################################\n",
      "AssemblyResolution.cs\n",
      "AssemblyResolver.cs\n",
      "BuildTask.cs\n",
      "BuildTask.Desktop.cs\n",
      "DisposeAction.cs\n",
      "EnumerableExtensions.cs\n",
      "EnumExtensions.cs\n",
      "ArgumentEscaper.cs\n",
      "Command.cs\n",
      "CommandFactory.cs\n",
      "\n",
      "\n",
      "####################################\n",
      "Number of files for N-grams:\n",
      "####################################\n",
      "201706 files.\n"
     ]
    }
   ],
   "source": [
    "# Define constants.\n",
    "ROOT_DIRECTORY = \"D:\\DsTCC\"\n",
    "\n",
    "# Get all file names.\n",
    "complete_file_names = get_all_c_sharp_complete_file_names_for_each_class(ROOT_DIRECTORY)\n",
    "\n",
    "# Print first 10 files.\n",
    "print_info(\"First 10 files:\")\n",
    "\n",
    "for file_name in complete_file_names[:10]:\n",
    "    print(ntpath.basename(file_name))\n",
    "\n",
    "# Print total number of files.\n",
    "print_info(\"Number of files for N-grams:\", new_line=True)\n",
    "print(\"%s files.\" % (len(complete_file_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get source code of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "Source code of first C# file class:\n",
      "####################################\n",
      "// Licensed to the .NET Foundation under one or more agreements.\n",
      "// The .NET Foundation licenses this file to you under the MIT license.\n",
      "\n",
      "#if NET472\n",
      "\n",
      "using System;\n",
      "using System.Collections.Generic;\n",
      "using System.IO;\n",
      "using System.Reflection;\n",
      "using Microsoft.Build.Framework;\n",
      "using Microsoft.Build.Utilities;\n",
      "\n",
      "namespace Microsoft.DotNet\n",
      "{\n",
      "    internal static class AssemblyResolution\n",
      "    {\n",
      "        internal static TaskLoggingHelper Log;\n",
      "\n",
      "        public static void Initialize()\n",
      "        {\n",
      "            AppDomain.CurrentDomain.AssemblyResolve += AssemblyResolve;\n",
      "        }\n",
      "\n",
      "        private static Assembly AssemblyResolve(object sender, ResolveEventArgs args)\n",
      "        {\n",
      "            var name = new AssemblyName(args.Name);\n",
      "\n",
      "            if (!name.Name.Equals(\"System.Collections.Immutable\", StringComparison.OrdinalIgnoreCase))\n",
      "            {\n",
      "                return null;\n",
      "            }\n",
      "\n",
      "            var fullPath = Path.Combine(AppDomain.CurrentDomain.BaseDirectory, \"System.Collections.Immutable.dll\");\n",
      "\n",
      "            Assembly sci;\n",
      "            try\n",
      "            {\n",
      "                sci = Assembly.LoadFile(fullPath);\n",
      "            }\n",
      "            catch (Exception e)\n",
      "            {\n",
      "                Log?.LogWarning($\"AssemblyResolve: exception while loading '{fullPath}': {e.Message}\");\n",
      "                return null;\n",
      "            }\n",
      "\n",
      "            if (name.Version <= sci.GetName().Version)\n",
      "            {\n",
      "                Log?.LogMessage(MessageImportance.Low, $\"AssemblyResolve: loaded '{fullPath}' to {AppDomain.CurrentDomain.FriendlyName}\");\n",
      "                return sci;\n",
      "            }\n",
      "\n",
      "            return null;\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "#endif\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c_sharp_code_corpus = get_content_for_each_file(complete_file_names)\n",
    "print_info(\"Source code of first C# file class:\", c_sharp_code_corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = tokenize_all_files(c_sharp_code_corpus, first_x_corpus=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export tokens to backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(tokens, 'tokens_bkp.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tokens from backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_from_data_file('tokens_bkp.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "First 10 tokens:\n",
      "####################################\n",
      "['//', 'Licensed', 'to', 'the', '.NET', 'Foundation', 'under', 'one', 'or', 'more', 'agreements', '.']\n",
      "['//', 'The', '.NET', 'Foundation', 'licenses', 'this', 'file', 'to', 'you', 'under', 'the', 'MIT', 'license', '.']\n",
      "['#', 'if', 'NET|mask_number|']\n",
      "['using', 'System', ';']\n",
      "['using', 'System.Collections.Generic', ';']\n",
      "['using', 'System.IO', ';']\n",
      "['using', 'System.Reflection', ';']\n",
      "['using', 'Microsoft.Build.Framework', ';']\n",
      "['using', 'Microsoft.Build.Utilities', ';']\n",
      "['namespace', 'Microsoft.DotNet']\n"
     ]
    }
   ],
   "source": [
    "print_info(\"First 10 tokens:\")\n",
    "for token in flatten_list(tokens)[:10]:\n",
    "    print(token) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get tokens and vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 3\n",
    "new_data_tokens, vocabulary = processing_vocabulary_and_unknown(tokens, min_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get n-grams count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTITY_NGRAMS_TO_GENERATE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_counts_list = []\n",
    "for n in range(1, QUANTITY_NGRAMS_TO_GENERATE + 1):\n",
    "    n_model_counts = count_n_grams(new_data_tokens, n)\n",
    "    n_gram_counts_list.append(n_model_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display 5 words combinations that appeared the most in each n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "1-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>)</td>\n",
       "      <td>23203367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(</td>\n",
       "      <td>23202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>11792814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>;</td>\n",
       "      <td>10033382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>=</td>\n",
       "      <td>5635404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Words     Count\n",
       "0     )  23203367\n",
       "1     (  23202300\n",
       "2     ,  11792814\n",
       "3     ;  10033382\n",
       "4     =   5635404"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "2-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((</td>\n",
       "      <td>9146342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>);</td>\n",
       "      <td>5200301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>;}</td>\n",
       "      <td>2957248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>)+</td>\n",
       "      <td>2927367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>){</td>\n",
       "      <td>2854688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Words    Count\n",
       "0    ((  9146342\n",
       "1    );  5200301\n",
       "2    ;}  2957248\n",
       "3    )+  2927367\n",
       "4    ){  2854688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "3-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((</td>\n",
       "      <td>8644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>);}</td>\n",
       "      <td>1520228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[|mask_number|]</td>\n",
       "      <td>1325311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,|mask_number|x|mask_number|,</td>\n",
       "      <td>1293989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>|mask_number|])</td>\n",
       "      <td>1059917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Words    Count\n",
       "0                            (((  8644068\n",
       "1                            );}  1520228\n",
       "2                [|mask_number|]  1325311\n",
       "3  ,|mask_number|x|mask_number|,  1293989\n",
       "4                |mask_number|])  1059917"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "4-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((((</td>\n",
       "      <td>8554307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[|mask_number|])</td>\n",
       "      <td>1042245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>|mask_number|x|mask_number|,|mask_number|x|mas...</td>\n",
       "      <td>1020632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,|mask_number|x|mask_number|,|mask_number|x|ma...</td>\n",
       "      <td>1016741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--------</td>\n",
       "      <td>901374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Words    Count\n",
       "0                                               ((((  8554307\n",
       "1                                   [|mask_number|])  1042245\n",
       "2  |mask_number|x|mask_number|,|mask_number|x|mas...  1020632\n",
       "3  ,|mask_number|x|mask_number|,|mask_number|x|ma...  1016741\n",
       "4                                           --------   901374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "5-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(((((</td>\n",
       "      <td>8489794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,|mask_number|x|mask_number|,|mask_number|x|ma...</td>\n",
       "      <td>1014999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>----------</td>\n",
       "      <td>865768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*****</td>\n",
       "      <td>863235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>|mask_number|x|mask_number|,|mask_number|x|mas...</td>\n",
       "      <td>832296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Words    Count\n",
       "0                                              (((((  8489794\n",
       "1  ,|mask_number|x|mask_number|,|mask_number|x|ma...  1014999\n",
       "2                                         ----------   865768\n",
       "3                                              *****   863235\n",
       "4  |mask_number|x|mask_number|,|mask_number|x|mas...   832296"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "display_5_combinations_top_most(n_gram_counts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export ngrams x counts list, new data tokens and vocabulary to backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(n_gram_counts_list, 'n_gram_counts_list.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(new_data_tokens, 'new_data_tokens.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_list_to_data_file(vocabulary, 'vocabulary.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ngrams x counts list, new data tokens and vocabulary from backup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_counts_list = load_from_data_file('n_gram_counts_list.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_tokens = load_from_data_file('new_data_tokens.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = load_from_data_file('vocabulary.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get suggestions recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>previous_tokens</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[public]</td>\n",
       "      <td>[[(static, 0.13878612711693716), (void, 0.1022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[public, static]</td>\n",
       "      <td>[[(void, 0.05360907345975815), (string, 0.0453...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>[public, static, void]</td>\n",
       "      <td>[[(&lt;unk&gt;, 0.02085204659309168), (Main, 0.00996...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>[public, static, void, &lt;unk&gt;]</td>\n",
       "      <td>[[((, 0.021744681053016246), (&lt;, 0.00024488749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>[public, static, void, &lt;unk&gt;, (]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>6</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;, T]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>6</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;, ChannelType]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>6</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;, //]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>6</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;, Licensed]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>6</td>\n",
       "      <td>[public, int, &lt;unk&gt;, &lt;, to]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ngram                       previous_tokens  \\\n",
       "0        2                              [public]   \n",
       "1        3                      [public, static]   \n",
       "2        4                [public, static, void]   \n",
       "3        5         [public, static, void, <unk>]   \n",
       "4        6      [public, static, void, <unk>, (]   \n",
       "..     ...                                   ...   \n",
       "776      6            [public, int, <unk>, <, T]   \n",
       "777      6  [public, int, <unk>, <, ChannelType]   \n",
       "778      6           [public, int, <unk>, <, //]   \n",
       "779      6     [public, int, <unk>, <, Licensed]   \n",
       "780      6           [public, int, <unk>, <, to]   \n",
       "\n",
       "                                           suggestions  \n",
       "0    [[(static, 0.13878612711693716), (void, 0.1022...  \n",
       "1    [[(void, 0.05360907345975815), (string, 0.0453...  \n",
       "2    [[(<unk>, 0.02085204659309168), (Main, 0.00996...  \n",
       "3    [[((, 0.021744681053016246), (<, 0.00024488749...  \n",
       "4                                                   []  \n",
       "..                                                 ...  \n",
       "776                                                 []  \n",
       "777                                                 []  \n",
       "778                                                 []  \n",
       "779                                                 []  \n",
       "780                                                 []  \n",
       "\n",
       "[781 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "suggestions_for_all_grams = []\n",
    "\n",
    "# First word to generate suggestion in 5 levels\n",
    "previous_tokens = [\"public\"]\n",
    "\n",
    "get_suggestions_recursively(previous_tokens, \n",
    "                            n_gram_counts_list, \n",
    "                            vocabulary, \n",
    "                            suggestions_for_all_grams, \n",
    "                            QUANTITY_NGRAMS_TO_GENERATE)\n",
    "    \n",
    "df = pd.DataFrame(suggestions_for_all_grams, columns=['ngram', 'previous_tokens', 'suggestions'])\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format each n-gram level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### N-grams suggested for the first token typed (public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "2-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_0eb38_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_0eb38_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_0eb38_row0_col0\" class=\"data row0 col0\" >public</td>\n",
       "                        <td id=\"T_0eb38_row0_col1\" class=\"data row0 col1\" >public static</td>\n",
       "                        <td id=\"T_0eb38_row0_col2\" class=\"data row0 col2\" >13.88%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0eb38_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_0eb38_row1_col0\" class=\"data row1 col0\" >public</td>\n",
       "                        <td id=\"T_0eb38_row1_col1\" class=\"data row1 col1\" >public void</td>\n",
       "                        <td id=\"T_0eb38_row1_col2\" class=\"data row1 col2\" >10.22%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0eb38_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_0eb38_row2_col0\" class=\"data row2 col0\" >public</td>\n",
       "                        <td id=\"T_0eb38_row2_col1\" class=\"data row2 col1\" >public class</td>\n",
       "                        <td id=\"T_0eb38_row2_col2\" class=\"data row2 col2\" >5.02%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0eb38_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_0eb38_row3_col0\" class=\"data row3 col0\" >public</td>\n",
       "                        <td id=\"T_0eb38_row3_col1\" class=\"data row3 col1\" >public override</td>\n",
       "                        <td id=\"T_0eb38_row3_col2\" class=\"data row3 col2\" >4.91%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_0eb38_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_0eb38_row4_col0\" class=\"data row4 col0\" >public</td>\n",
       "                        <td id=\"T_0eb38_row4_col1\" class=\"data row4 col1\" >public int</td>\n",
       "                        <td id=\"T_0eb38_row4_col2\" class=\"data row4 col2\" >4.00%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21cbb864820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "3-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b8cc6_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b8cc6_level0_row0\" class=\"row_heading level0 row0\" >5</th>\n",
       "                        <td id=\"T_b8cc6_row0_col0\" class=\"data row0 col0\" >public void</td>\n",
       "                        <td id=\"T_b8cc6_row0_col1\" class=\"data row0 col1\" >public void <unk></td>\n",
       "                        <td id=\"T_b8cc6_row0_col2\" class=\"data row0 col2\" >10.30%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8cc6_level0_row1\" class=\"row_heading level0 row1\" >20</th>\n",
       "                        <td id=\"T_b8cc6_row1_col0\" class=\"data row1 col0\" >public int</td>\n",
       "                        <td id=\"T_b8cc6_row1_col1\" class=\"data row1 col1\" >public int m|mask_number|</td>\n",
       "                        <td id=\"T_b8cc6_row1_col2\" class=\"data row1 col2\" >5.61%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8cc6_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "                        <td id=\"T_b8cc6_row2_col0\" class=\"data row2 col0\" >public static</td>\n",
       "                        <td id=\"T_b8cc6_row2_col1\" class=\"data row2 col1\" >public static void</td>\n",
       "                        <td id=\"T_b8cc6_row2_col2\" class=\"data row2 col2\" >5.36%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8cc6_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
       "                        <td id=\"T_b8cc6_row3_col0\" class=\"data row3 col0\" >public static</td>\n",
       "                        <td id=\"T_b8cc6_row3_col1\" class=\"data row3 col1\" >public static string</td>\n",
       "                        <td id=\"T_b8cc6_row3_col2\" class=\"data row3 col2\" >4.53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b8cc6_level0_row4\" class=\"row_heading level0 row4\" >10</th>\n",
       "                        <td id=\"T_b8cc6_row4_col0\" class=\"data row4 col0\" >public class</td>\n",
       "                        <td id=\"T_b8cc6_row4_col1\" class=\"data row4 col1\" >public class Class|mask_number|</td>\n",
       "                        <td id=\"T_b8cc6_row4_col2\" class=\"data row4 col2\" >4.42%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21cbeb47b20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "4-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_67af1_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_67af1_level0_row0\" class=\"row_heading level0 row0\" >25</th>\n",
       "                        <td id=\"T_67af1_row0_col0\" class=\"data row0 col0\" >public void <unk></td>\n",
       "                        <td id=\"T_67af1_row0_col1\" class=\"data row0 col1\" >public void <unk> (</td>\n",
       "                        <td id=\"T_67af1_row0_col2\" class=\"data row0 col2\" >12.10%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_67af1_level0_row1\" class=\"row_heading level0 row1\" >100</th>\n",
       "                        <td id=\"T_67af1_row1_col0\" class=\"data row1 col0\" >public int m|mask_number|</td>\n",
       "                        <td id=\"T_67af1_row1_col1\" class=\"data row1 col1\" >public int m|mask_number| =</td>\n",
       "                        <td id=\"T_67af1_row1_col2\" class=\"data row1 col2\" >5.98%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_67af1_level0_row2\" class=\"row_heading level0 row2\" >50</th>\n",
       "                        <td id=\"T_67af1_row2_col0\" class=\"data row2 col0\" >public class Class|mask_number|</td>\n",
       "                        <td id=\"T_67af1_row2_col1\" class=\"data row2 col1\" >public class Class|mask_number| {</td>\n",
       "                        <td id=\"T_67af1_row2_col2\" class=\"data row2 col2\" >4.90%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_67af1_level0_row3\" class=\"row_heading level0 row3\" >5</th>\n",
       "                        <td id=\"T_67af1_row3_col0\" class=\"data row3 col0\" >public static string</td>\n",
       "                        <td id=\"T_67af1_row3_col1\" class=\"data row3 col1\" >public static string Property</td>\n",
       "                        <td id=\"T_67af1_row3_col2\" class=\"data row3 col2\" >4.73%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_67af1_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "                        <td id=\"T_67af1_row4_col0\" class=\"data row4 col0\" >public static void</td>\n",
       "                        <td id=\"T_67af1_row4_col1\" class=\"data row4 col1\" >public static void <unk></td>\n",
       "                        <td id=\"T_67af1_row4_col2\" class=\"data row4 col2\" >2.09%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21cbeb7dfa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "####################################\n",
      "5-gram(s):\n",
      "####################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_b2308_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Previous_Tokens</th>        <th class=\"col_heading level0 col1\" >Suggestion</th>        <th class=\"col_heading level0 col2\" >Probability</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b2308_level0_row0\" class=\"row_heading level0 row0\" >125</th>\n",
       "                        <td id=\"T_b2308_row0_col0\" class=\"data row0 col0\" >public void <unk> (</td>\n",
       "                        <td id=\"T_b2308_row0_col1\" class=\"data row0 col1\" >public void <unk> ( )</td>\n",
       "                        <td id=\"T_b2308_row0_col2\" class=\"data row0 col2\" >9.93%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b2308_level0_row1\" class=\"row_heading level0 row1\" >500</th>\n",
       "                        <td id=\"T_b2308_row1_col0\" class=\"data row1 col0\" >public int m|mask_number| =</td>\n",
       "                        <td id=\"T_b2308_row1_col1\" class=\"data row1 col1\" >public int m|mask_number| = |mask_number|</td>\n",
       "                        <td id=\"T_b2308_row1_col2\" class=\"data row1 col2\" >5.98%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b2308_level0_row2\" class=\"row_heading level0 row2\" >250</th>\n",
       "                        <td id=\"T_b2308_row2_col0\" class=\"data row2 col0\" >public class Class|mask_number| {</td>\n",
       "                        <td id=\"T_b2308_row2_col1\" class=\"data row2 col1\" >public class Class|mask_number| { public</td>\n",
       "                        <td id=\"T_b2308_row2_col2\" class=\"data row2 col2\" >4.82%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b2308_level0_row3\" class=\"row_heading level0 row3\" >25</th>\n",
       "                        <td id=\"T_b2308_row3_col0\" class=\"data row3 col0\" >public static string Property</td>\n",
       "                        <td id=\"T_b2308_row3_col1\" class=\"data row3 col1\" >public static string Property =</td>\n",
       "                        <td id=\"T_b2308_row3_col2\" class=\"data row3 col2\" >4.80%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b2308_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "                        <td id=\"T_b2308_row4_col0\" class=\"data row4 col0\" >public static void <unk></td>\n",
       "                        <td id=\"T_b2308_row4_col1\" class=\"data row4 col1\" >public static void <unk> (</td>\n",
       "                        <td id=\"T_b2308_row4_col2\" class=\"data row4 col2\" >2.17%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x21cbf0474c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "df_formated = df.copy()\n",
    "\n",
    "for i in range(2, QUANTITY_NGRAMS_TO_GENERATE + 1):\n",
    "\n",
    "    print_info(\"%s-gram(s):\" % (i))\n",
    "    \n",
    "    df_ngrams = df_formated.query(\"ngram==%s\" % (i))\n",
    "    \n",
    "    formated_results = format_words_and_probability(df_ngrams)\n",
    "    \n",
    "    df_ngrams_formated = pd.DataFrame(formated_results, columns=['Previous_Tokens', 'Suggestion', 'Probability'])\n",
    "    \n",
    "    df_top_5 = df_ngrams_formated.sort_values(by='Probability',ascending=False).iloc[:5,:]\n",
    "    df_top_5 = df_top_5.style.format({'Probability': \"{:.2%}\"})\n",
    "    display(df_top_5)\n",
    "    \n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with common tokens C#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 previous token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_save_suggestions_from_csv_file(PATH_TO_TEST_FILE_1_WORD, PATH_TO_SAVE_SUGGESTIONS_1_WORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 previous token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_save_suggestions_from_csv_file(PATH_TO_TEST_FILE_2_WORD, PATH_TO_SAVE_SUGGESTIONS_2_WORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 previous token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_save_suggestions_from_csv_file(PATH_TO_TEST_FILE_3_WORD, PATH_TO_SAVE_SUGGESTIONS_3_WORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 previous token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_and_save_suggestions_from_csv_file(PATH_TO_TEST_FILE_4_WORD, PATH_TO_SAVE_SUGGESTIONS_4_WORD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
